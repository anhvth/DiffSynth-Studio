{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93bd316-4580-4de9-951b-0b97b26fa0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/anhvth5/vision-projects/DiffSynth-Studio\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /anhvth5/vision-projects/DiffSynth-Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.ExVideo.ExVideo_svd_train_custom import *\n",
    "from diffsynth.models.svd_unet import SVDUNet, PushBlock, PopBlock, PopMixBlock\n",
    "from avcv.all import *\n",
    "from fastcore.all import patch\n",
    "args = parse_args().parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3edc7d-b1a2-45c6-98a9-1d0aff199b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_frames = 8\n",
    "args.steps_per_epoch = 500\n",
    "args.pretrained_path =  \"models/stable_video_diffusion/svd_xt.safetensors\"\n",
    "args.height = 512\n",
    "args.width = 288\n",
    "args.learning_rate = 1e-5\n",
    "\n",
    "ds_path = './datasets/tiktokdance/'\n",
    "steps_per_epoch = 500\n",
    "#-----\n",
    "dataset = TextVideoDataset(\n",
    "        ds_path,\n",
    "        os.path.join(ds_path, \"metadata.json\"),\n",
    "        training_shapes=[(args.num_frames, 1, args.num_frames, 512, 384)],\n",
    "        steps_per_epoch=args.steps_per_epoch,\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7bc893c-dbea-4612-824e-06a1bda7bcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63adb362-e6e2-43d2-926e-c29caded720e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 µs, sys: 70 µs, total: 309 µs\n",
      "Wall time: 313 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not 'model' in dir():\n",
    "    model = LightningModel(\n",
    "        learning_rate=args.learning_rate,\n",
    "        svd_ckpt_path=args.pretrained_path,\n",
    "        add_positional_conv=args.num_frames,\n",
    "        contrast_enhance_scale=args.contrast_enhance_scale\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a2b075-6623-4de4-ab17-f55e5d8425a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffsynth.controlnets.processors import Annotator\n",
    "processor = Annotator('openpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cbc25a7-a0ca-449a-abe0-2a31091faed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9385aad0-ecdc-4938-9e49-8ca6388b7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_frames = dataset.raw_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57b33e79-53ad-46c8-be02-fdb4e2fd1ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac712d-6acf-4860-ad77-def30db7a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619551c-e63a-4402-8c50-619608aae652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def extend_layer(old_layer, num_new_dim=4):\n",
    "    if not isinstance(old_layer, nn.Conv2d):\n",
    "        raise ValueError(\"The layer must be an instance of nn.Conv2d\")\n",
    "\n",
    "    old_in_channels = 8\n",
    "    new_in_channels = 12\n",
    "    new_layer = nn.Conv2d(new_in_channels, \n",
    "                          old_layer.out_channels, \n",
    "                          kernel_size=old_layer.kernel_size, \n",
    "                          stride=old_layer.stride, \n",
    "                          padding=old_layer.padding, \n",
    "                          dilation=old_layer.dilation, \n",
    "                          groups=old_layer.groups, \n",
    "                          bias=old_layer.bias is not None,\n",
    "                          device=old_layer.weight.device,\n",
    "                          dtype=old_layer.weight.dtype)\n",
    "\n",
    "    # Copy the existing weights\n",
    "    with torch.no_grad():\n",
    "        new_layer.weight[:, :8, :, :] = old_layer.weight[:,:8].clone()\n",
    "    \n",
    "        new_layer.weight[:, 8:12, :, :] = old_layer.weight[:, 4:8, :, :].clone()\n",
    "\n",
    "        if old_layer.bias is not None:\n",
    "            new_layer.bias = nn.Parameter(old_layer.bias.clone())\n",
    "\n",
    "    return new_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a81be-417c-42a1-9ade-df574ee2fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.unet.requires_grad_(False)\n",
    "model.unet.conv_in = extend_layer(model.unet.conv_in)\n",
    "model.unet.conv_in.requires_grad_(True)\n",
    "model.half().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7329c6e-b7ef-40e0-b5f5-151d7110990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67fa2a-87d0-48f7-9d36-20c8227f39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc61910-6009-427f-bf66-63137d6d4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = batch[\"frames_0\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295a23e-55e5-4259-90fd-fa9ac7bcf21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09436067-9a42-44c6-be1a-50818c00043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    loss = model.calculate_loss(frames.cuda().half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1feb00-849b-4ff0-b6b0-b61065c569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c763fb-efe1-4811-8780-4ac35c61fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
