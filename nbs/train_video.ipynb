{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93bd316-4580-4de9-951b-0b97b26fa0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anhvth5/vision-projects/DiffSynth-Studio\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /anhvth5/vision-projects/DiffSynth-Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0991c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.ExVideo.ExVideo_svd_train_custom import *\n",
    "from diffsynth.models.svd_unet import SVDUNet, PushBlock, PopBlock, PopMixBlock\n",
    "from avcv.all import *\n",
    "from fastcore.all import patch\n",
    "args = parse_args().parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3edc7d-b1a2-45c6-98a9-1d0aff199b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_frames = 8\n",
    "args.steps_per_epoch = 500\n",
    "args.pretrained_path =  \"models/stable_video_diffusion/svd_xt.safetensors\"\n",
    "args.height = 512\n",
    "args.width = 288\n",
    "args.learning_rate = 1e-5\n",
    "\n",
    "ds_path = './datasets/tiktokdance/'\n",
    "steps_per_epoch = 500\n",
    "#-----\n",
    "dataset = TextVideoDataset(\n",
    "        ds_path,\n",
    "        os.path.join(ds_path, \"metadata.json\"),\n",
    "        training_shapes=[(args.num_frames, 1, args.num_frames, 512, 384)],\n",
    "        steps_per_epoch=args.steps_per_epoch,\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63adb362-e6e2-43d2-926e-c29caded720e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 684 ms, sys: 719 ms, total: 1.4 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not 'model' in dir():\n",
    "    model = LightningModel(\n",
    "        learning_rate=args.learning_rate,\n",
    "        svd_ckpt_path=args.pretrained_path,\n",
    "        add_positional_conv=args.num_frames,\n",
    "        contrast_enhance_scale=args.contrast_enhance_scale\n",
    "    )\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a21e0ae-f5aa-4f8c-8935-ff03af06e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "955be212-3897-4fc4-bc01-08948db57799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8, 512, 384]), torch.Size([3, 8, 512, 384]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = batch[\"frames_0\"][0]\n",
    "control_frames = batch['control_frames_0'][0]\n",
    "frames.shape, control_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89a1c3-e2cb-479e-81fa-858d1be15442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/anhvth5/vision-projects/DiffSynth-Studio/examples/ExVideo/ExVideo_svd_train_custom.py\u001b[0m(372)\u001b[0;36mcalculate_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    371 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 372 \u001b[0;31m            \u001b[0mcontrol_latents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_video_with_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_frames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    373 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  control_frames.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 512, 384])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    loss, reweighted_loss = model.calculate_loss(frames.cuda(), control_frames.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acdcd6c3-561e-44fb-a0a6-621c07dd1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5097, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc61910-6009-427f-bf66-63137d6d4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = batch[\"frames_0\"][0]\n",
    "control_frames = batch['control_frames_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d295a23e-55e5-4259-90fd-fa9ac7bcf21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8, 512, 384]), torch.Size([1, 1, 3, 512, 384]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape, control_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09436067-9a42-44c6-be1a-50818c00043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    loss = model.calculate_loss(frames.cuda().half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1feb00-849b-4ff0-b6b0-b61065c569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c763fb-efe1-4811-8780-4ac35c61fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
